{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"471d9060-044d-4570-ab66-f37affa0b84b","showTitle":false,"title":""}},"source":["## Section 1) Mount Azure storage blob container"]},{"cell_type":"code","execution_count":1,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"92e5621b-6b31-4743-87c1-3182956185a9","showTitle":false,"title":""}},"outputs":[],"source":["# Mount Blob to DBFS\n","dbutils.fs.mount(\n","  source = \"wasbs://datalake@dsba6190storageepsilon.blob.core.windows.net/\",\n","  mount_point = \"/mnt/epsilon/\",\n","  extra_configs = {\"fs.azure.account.key.dsba6190storageepsilon.blob.core.windows.net\": \"HB87PDIxoCmvJYrC5JqMzEic3ySYwEll03NoGfRtJiviX6oQmS1Khnhz4wjIP30r41vIGIn5Cqo9+AStVPZD5Q==\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"63ca8dd8-2e6f-40e2-8a71-dedd5de47eb3","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/mnt/Delta/</td><td>wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/</td><td></td></tr><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/mnt/epsilon/</td><td>wasbs://datalake@dsba6190storageepsilon.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/delta-sai/</td><td>wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/gamma/</td><td>wasbs://datawarehouse@dsba6190storagegamma.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/zeta/</td><td>wasbs://datalake@dsba6190storageks.blob.core.windows.net/</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td></td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td></td></tr><tr><td>/mnt/<beta>/</td><td>wasbs://data@dsba6190storagebeta.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/beta/</td><td>wasbs://data@dsba6190storagebeta.blob.core.windows.net/</td><td></td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td></td></tr><tr><td>/mnt/dsba6190-gamma-rg/</td><td>wasbs://datawarehouse@dsba6190storagegamma.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/DELTA/</td><td>wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/instructor/</td><td>wasbs://datalake@dsba6190storageinst.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/alpha/</td><td>wasbs://datalake@dsba6190storagealpha.blob.core.windows.net/</td><td></td></tr><tr><td>/mnt/delta/</td><td>wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td></td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[["/mnt/Delta/","wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/",""],["/databricks-datasets","databricks-datasets",""],["/mnt/epsilon/","wasbs://datalake@dsba6190storageepsilon.blob.core.windows.net/",""],["/mnt/delta-sai/","wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/",""],["/mnt/gamma/","wasbs://datawarehouse@dsba6190storagegamma.blob.core.windows.net/",""],["/mnt/zeta/","wasbs://datalake@dsba6190storageks.blob.core.windows.net/",""],["/databricks/mlflow-tracking","databricks/mlflow-tracking",""],["/databricks-results","databricks-results",""],["/mnt/<beta>/","wasbs://data@dsba6190storagebeta.blob.core.windows.net/",""],["/mnt/beta/","wasbs://data@dsba6190storagebeta.blob.core.windows.net/",""],["/databricks/mlflow-registry","databricks/mlflow-registry",""],["/mnt/dsba6190-gamma-rg/","wasbs://datawarehouse@dsba6190storagegamma.blob.core.windows.net/",""],["/mnt/DELTA/","wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/",""],["/mnt/instructor/","wasbs://datalake@dsba6190storageinst.blob.core.windows.net/",""],["/mnt/alpha/","wasbs://datalake@dsba6190storagealpha.blob.core.windows.net/",""],["/mnt/delta/","wasbs://datalake@dsba6190storagedelta.blob.core.windows.net/",""],["/","DatabricksRoot",""]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"mountPoint","type":"\"string\""},{"metadata":"{}","name":"source","type":"\"string\""},{"metadata":"{}","name":"encryptionType","type":"\"string\""}],"type":"table"}},"output_type":"display_data"}],"source":["#dbutils.fs.ls(\"/mnt/\")\n","display(dbutils.fs.mounts())"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5977c071-848d-4319-920e-e481457a2e24","showTitle":false,"title":""}},"source":["## Section 1b) Read in Your Data\n","\n","### Description of the Data: \n","The dataset is credited to Ronny Kohavi and Barry Becker and was drawn from the 1994 United States Census Bureau data and involves using personal details such as education level to predict whether an individual will earn more or less than $50,000 per year.\n","### Data Source: \n","https://archive.ics.uci.edu/ml/datasets/adult"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"16c598de-69a6-47c6-abc5-fa0d49be0eeb","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["+---+---------+------+----------+-------------+--------------+------------------+--------------+------+---+------------+------------+--------------+--------------+------+\n","|age|workclass|fnlwgt| education|education-num|marital-status|        occupation|  relationship|  race|sex|capital-gain|capital-loss|hours-per-week|native-country|Salary|\n","+---+---------+------+----------+-------------+--------------+------------------+--------------+------+---+------------+------------+--------------+--------------+------+\n","| 39|     Govt| 77516| Bachelors|           13| Never-married|      Adm-clerical| Not-in-family| White|  0|        2174|           0|            40| United-States|     1|\n","| 50| employed| 83311| Bachelors|           13|       Married|   Exec-managerial|       Husband| White|  0|           0|           0|            13| United-States|     1|\n","| 38|  Private|215646|   HS-grad|            9|      Divorced| Handlers-cleaners| Not-in-family| White|  0|           0|           0|            40| United-States|     1|\n","| 53|  Private|234721| schooling|            7|       Married| Handlers-cleaners|       Husband| Black|  0|           0|           0|            40| United-States|     1|\n","| 28|  Private|338409| Bachelors|           13|       Married|    Prof-specialty|          Wife| Black|  1|           0|           0|            40|          Cuba|     1|\n","+---+---------+------+----------+-------------+--------------+------------------+--------------+------+---+------------+------------+--------------+--------------+------+\n","only showing top 5 rows\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"+---+---------+------+----------+-------------+--------------+------------------+--------------+------+---+------------+------------+--------------+--------------+------+\n|age|workclass|fnlwgt| education|education-num|marital-status|        occupation|  relationship|  race|sex|capital-gain|capital-loss|hours-per-week|native-country|Salary|\n+---+---------+------+----------+-------------+--------------+------------------+--------------+------+---+------------+------------+--------------+--------------+------+\n| 39|     Govt| 77516| Bachelors|           13| Never-married|      Adm-clerical| Not-in-family| White|  0|        2174|           0|            40| United-States|     1|\n| 50| employed| 83311| Bachelors|           13|       Married|   Exec-managerial|       Husband| White|  0|           0|           0|            13| United-States|     1|\n| 38|  Private|215646|   HS-grad|            9|      Divorced| Handlers-cleaners| Not-in-family| White|  0|           0|           0|            40| United-States|     1|\n| 53|  Private|234721| schooling|            7|       Married| Handlers-cleaners|       Husband| Black|  0|           0|           0|            40| United-States|     1|\n| 28|  Private|338409| Bachelors|           13|       Married|    Prof-specialty|          Wife| Black|  1|           0|           0|            40|          Cuba|     1|\n+---+---------+------+----------+-------------+--------------+------------------+--------------+------+---+------------+------------+--------------+--------------+------+\nonly showing top 5 rows\n\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["df = sqlContext.read.format('csv') \\\n","                    .options(header='true', inferSchema='true', delimiter= ',') \\\n","                    .load('/mnt/epsilon/adult.csv')\n","\n","\n","#df.describe()\n","df=df.withColumnRenamed(\"occupation6\",\"occupation\")\n","df=df.withColumnRenamed(\"occupation7\",\"relationship\")\n","df.show(5)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2e382165-df32-4c0e-b5c7-c41ce14e76c1","showTitle":false,"title":""}},"source":["## Section 2) Shaping the Data for Machine Learning\n","Transform the data for use in machine learning. This includes One Hot Encoding, Vectorization, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4cbac7a0-a15a-42f8-9280-7b80be67e928","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["workclass\n","education\n","marital-status\n","occupation\n","relationship\n","race\n","sex\n","native-country\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"workclass\neducation\nmarital-status\noccupation\nrelationship\nrace\nsex\nnative-country\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n","\n","#Define which columns are numerical versus categorical\n","\n","label = \"Salary\"\n","categoricalColumns = [\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]\n","\n","numericalColumns = [\"age\",\"fnlwgt\",\"education-num\",\"capital-gain\",\"capital-loss\",\"hours-per-week\"]\n","\n","#categoricalColumnsclassVec = [\"col1classVec\",\n","#                              \"col2classVec\"]\n","categoricalColumnsclassVec = [c + \"classVec\" for c in categoricalColumns]\n","\n","#Set up stages\n","stages = []\n","\n","#Index the categorical columns and perform One Hot Encoding\n","for categoricalColumn in categoricalColumns:\n","  print(categoricalColumn)\n","  ## Category Indexing with StringIndexer\n","  stringIndexer = StringIndexer(inputCol=categoricalColumn, outputCol = categoricalColumn+\"Index\").setHandleInvalid(\"skip\")\n","  ## Use OneHotEncoder to convert categorical variables into binary SparseVectors\n","  encoder = OneHotEncoder(inputCol=categoricalColumn+\"Index\", outputCol=categoricalColumn+\"classVec\")\n","  ## Add stages\n","  stages += [stringIndexer, encoder]\n","\n","## Convert label into label indices using the StringIndexer\n","label_stringIndexer = StringIndexer(inputCol = label, outputCol = \"label\").setHandleInvalid(\"skip\")\n","stages += [label_stringIndexer]\n","\n","\n","##Assemble the data together as a vector\n","assemblerInputs = categoricalColumnsclassVec + numericalColumns\n","assembler = VectorAssembler(inputCols = assemblerInputs, outputCol = \"features\")\n","\n","stages += [assembler]\n","\n","#Scale features using Normalization\n","from pyspark.ml.feature import StandardScaler\n","scaler = StandardScaler(inputCol = \"features\",\n","                        outputCol = \"scaledFeatures\",\n","                        withStd = True,\n","                        withMean = True)\n","stages += [scaler]\n","\n","prepPipeline = Pipeline().setStages(stages)\n","pipelineModel = prepPipeline.fit(df)\n","dataset = pipelineModel.transform(df)\n","\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"24c29131-231f-4371-9742-0d54691e8cb6","showTitle":false,"title":""}},"source":["## Section 3a) Create a Machine Learning Model\n","## Machine learning algorithms from Spark MLlib and train models using your data.\n","Logistic Regression & Random Forest\n","### Description of the Predictive Use Case: \n","Predicting whether an individual will earn more or less than $50,000 per year"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7cf26b97-5a56-4410-bb6f-119a4645a9ff","showTitle":false,"title":""}},"outputs":[],"source":["#Test train split on our dataset\n","train, test = dataset.randomSplit([0.70, 0.30], seed = 1111)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"3fda0f1a-1204-4f50-bdd8-29014afaf3d5","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["CrossValidatorModel_3bbae54541a0\n","Accuracy: 0.9040797820470264\n","/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n","  warnings.warn(\n","AUC: 0.8080818789687665\n","PR: 0.5114596617470211\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"CrossValidatorModel_3bbae54541a0\nAccuracy: 0.9040797820470264\n/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\nAUC: 0.8080818789687665\nPR: 0.5114596617470211\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["#Logistic Regression\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.mllib.evaluation import BinaryClassificationMetrics\n","#initialize logistic regression object\n","lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n","#Create a parameter grid for tuning the model\n","lrparamGrid = (ParamGridBuilder()\n","             .addGrid(lr.regParam, [0.01, 0.1, 0.5, 1.0, 2.0])\n","             .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n","             .addGrid(lr.maxIter, [1, 5, 10, 20, 50])\n","             .build())\n","#Define how you want the model to be evaluated\n","lrevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName = \"areaUnderROC\")\n","\n","#Define the type of cross-validation you want to perform\n","# Create 5-fold CrossValidator\n","lrcv = CrossValidator(estimator = lr,\n","                    estimatorParamMaps = lrparamGrid,\n","                    evaluator = lrevaluator,\n","                    numFolds = 5)\n","#Fit the model to the data\n","lrcvModel = lrcv.fit(train)\n","print(lrcvModel)\n","#Score the testing dataset using your fitted model for evaluation purposes\n","lrpredictions = lrcvModel.transform(test)\n","print('Accuracy:', lrevaluator.evaluate(lrpredictions))\n","print('AUC:', BinaryClassificationMetrics(lrpredictions['label','prediction'].rdd).areaUnderROC)\n","print('PR:', BinaryClassificationMetrics(lrpredictions['label','prediction'].rdd).areaUnderPR)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"49d52fe5-3e8f-4cde-8957-caf318f14d04","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["CrossValidatorModel_e167637407f3\n","Accuracy: 0.9040797820470264\n","AUC: 0.8080818789687665\n","PR: 0.5114596617470211\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"CrossValidatorModel_e167637407f3\nAccuracy: 0.9040797820470264\nAUC: 0.8080818789687665\nPR: 0.5114596617470211\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["#Naive Bayes Classifier\n","from pyspark.ml.classification import NaiveBayes\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.mllib.evaluation import BinaryClassificationMetrics\n","\n","#Initialize Naive Bayes object\n","nb = NaiveBayes(labelCol=\"label\", featuresCol=\"features\")\n","\n","#Create a parameter grid for tuning the model\n","nbparamGrid = (ParamGridBuilder()\n","               .addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n","               .build())\n","#Define how you want the model to be evaluated\n","nbevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n","\n","# Create 5-fold CrossValidator\n","nbcv = CrossValidator(estimator = nb,\n","                      estimatorParamMaps = nbparamGrid,\n","                      evaluator = nbevaluator,\n","                      numFolds = 5)\n","#fit the model to the data\n","nbcvModel = nbcv.fit(train)\n","print(nbcvModel)\n","\n","nbpredictions = nbcvModel.transform(test)\n","\n","print('Accuracy:', lrevaluator.evaluate(lrpredictions))\n","print('AUC:', BinaryClassificationMetrics(lrpredictions['label','prediction'].rdd).areaUnderROC)\n","print('PR:', BinaryClassificationMetrics(lrpredictions['label','prediction'].rdd).areaUnderPR)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0a6b4855-34d9-446a-a4b2-35fbdfd1fff0","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["CrossValidatorModel_e77eee1dbeb5\n","Accuracy: 0.7459087142411932\n","AUC: 0.8075382755086205\n","PR: 0.5311362363870251\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"CrossValidatorModel_e77eee1dbeb5\nAccuracy: 0.7459087142411932\nAUC: 0.8075382755086205\nPR: 0.5311362363870251\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","#initialize Decision tree object\n","dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n","\n","dtparamGrid = (ParamGridBuilder()\n","             .addGrid(dt.maxDepth, [2, 5, 10])\n","             .addGrid(dt.maxBins, [10, 20])\n","             .build())\n","\n","dtevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n","\n","# Create 5-fold CrossValidator\n","dtcv = CrossValidator(estimator = dt,\n","                      estimatorParamMaps = dtparamGrid,\n","                      evaluator = dtevaluator,\n","                      numFolds = 5)\n","\n","dtcvModel = dtcv.fit(train)\n","print(dtcvModel)\n","\n","dtpredictions = dtcvModel.transform(test)\n","\n","print('Accuracy:', dtevaluator.evaluate(dtpredictions))\n","print('AUC:', BinaryClassificationMetrics(dtpredictions['label','prediction'].rdd).areaUnderROC)\n","print('PR:', BinaryClassificationMetrics(dtpredictions['label','prediction'].rdd).areaUnderPR)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b715d3ef-5162-41fe-a858-52b67fcb3984","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["CrossValidatorModel_fafc39eb6435\n","RMSE: 0.9090756099767751\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"CrossValidatorModel_fafc39eb6435\nRMSE: 0.9090756099767751\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["##Random Forest\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","\n","rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n","rfparamGrid = (ParamGridBuilder().addGrid(rf.maxDepth, [2, 5, 10]).addGrid(rf.maxBins, [5, 10, 20]).addGrid(rf.numTrees, [5, 20, 50]).build())\n","rfevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n","\n","# Create 5-fold CrossValidator\n","rfcv = CrossValidator(estimator = rf,\n","                      estimatorParamMaps = rfparamGrid,\n","                      evaluator = rfevaluator,\n","                      numFolds = 5)\n","rfcvModel = rfcv.fit(train)\n","print(rfcvModel)\n","rfpredictions = rfcvModel.transform(test)\n","print('RMSE:', rfevaluator.evaluate(rfpredictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1d89fdde-bb67-4b76-8009-9a51da3684bf","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["CrossValidatorModel_c3696e2fa37e\n","Accuracy: 0.9156455363156804\n","AUC: 0.8302687102073987\n","PR: 0.5246391724649102\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"CrossValidatorModel_c3696e2fa37e\nAccuracy: 0.9156455363156804\nAUC: 0.8302687102073987\nPR: 0.5246391724649102\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["from pyspark.ml.classification import GBTClassifier\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","\n","gb = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n","\n","gbparamGrid = (ParamGridBuilder()\n","             .addGrid(gb.maxDepth, [2, 5, 10])\n","             .addGrid(gb.maxBins, [10, 20, 40])\n","             .addGrid(gb.maxIter, [5, 10, 20])\n","             .build())\n","\n","gbevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n","\n","# Create 5-fold CrossValidator\n","gbcv = CrossValidator(estimator = gb,\n","                      estimatorParamMaps = gbparamGrid,\n","                      evaluator = gbevaluator,\n","                      numFolds = 5)\n","\n","gbcvModel = gbcv.fit(train)\n","print(gbcvModel)\n","\n","gbpredictions = gbcvModel.transform(test)\n","\n","print('Accuracy:', gbevaluator.evaluate(gbpredictions))\n","print('AUC:', BinaryClassificationMetrics(gbpredictions['label','prediction'].rdd).areaUnderROC)\n","print('PR:', BinaryClassificationMetrics(gbpredictions['label','prediction'].rdd).areaUnderPR)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d20bb66a-f8da-4af4-9980-1f0460306125","showTitle":false,"title":""}},"source":["## Section 3b) Evaluate the Model(s)\n","\n","1. Evaluate the models and pick which of the algorithms worked the best and why.\n","\n","2. Report the best model and its parameters below."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"cd728fd9-8f94-4e35-a12b-126c931fc36c","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Model: lrpredictions\n","True Positives: 1308\n","True Negatives: 7005\n","False Positives: 450\n","False Negatives: 1027\n","Total: 9790\n","Accuracy: 0.8491317671092952\n","Recall: 0.5601713062098501\n","Precision:  0.7440273037542662\n","F1 score: 0.6391399951136086\n","AUC: 0.8080818789687665\n","Model: dtpredictions\n","True Positives: 1361\n","True Negatives: 6971\n","False Positives: 484\n","False Negatives: 974\n","Total: 9790\n","Accuracy: 0.8510725229826354\n","Recall: 0.5828693790149893\n","Precision:  0.737669376693767\n","F1 score: 0.6511961722488038\n","AUC: 0.8075382755086205\n","Model: rfpredictions\n","True Positives: 1248\n","True Negatives: 7104\n","False Positives: 351\n","False Negatives: 1087\n","Total: 9790\n","Accuracy: 0.8531154239019407\n","Recall: 0.5344753747323341\n","Precision:  0.7804878048780488\n","F1 score: 0.6344687341128622\n","AUC: 0.8238905878254242\n","Model: nbpredictions\n","True Positives: 558\n","True Negatives: 7136\n","False Positives: 319\n","False Negatives: 1777\n","Total: 9790\n","Accuracy: 0.7859039836567926\n","Recall: 0.23897216274089936\n","Precision:  0.636259977194983\n","F1 score: 0.34744707347447074\n","AUC: 0.7184441364713836\n","Model: gbpredictions\n","True Positives: 1324\n","True Negatives: 7093\n","False Positives: 362\n","False Negatives: 1011\n","Total: 9790\n","Accuracy: 0.8597548518896834\n","Recall: 0.5670235546038543\n","Precision:  0.7852906287069988\n","F1 score: 0.6585426510818204\n","AUC: 0.8302687102073987\n","\n","\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Model: lrpredictions\nTrue Positives: 1308\nTrue Negatives: 7005\nFalse Positives: 450\nFalse Negatives: 1027\nTotal: 9790\nAccuracy: 0.8491317671092952\nRecall: 0.5601713062098501\nPrecision:  0.7440273037542662\nF1 score: 0.6391399951136086\nAUC: 0.8080818789687665\nModel: dtpredictions\nTrue Positives: 1361\nTrue Negatives: 6971\nFalse Positives: 484\nFalse Negatives: 974\nTotal: 9790\nAccuracy: 0.8510725229826354\nRecall: 0.5828693790149893\nPrecision:  0.737669376693767\nF1 score: 0.6511961722488038\nAUC: 0.8075382755086205\nModel: rfpredictions\nTrue Positives: 1248\nTrue Negatives: 7104\nFalse Positives: 351\nFalse Negatives: 1087\nTotal: 9790\nAccuracy: 0.8531154239019407\nRecall: 0.5344753747323341\nPrecision:  0.7804878048780488\nF1 score: 0.6344687341128622\nAUC: 0.8238905878254242\nModel: nbpredictions\nTrue Positives: 558\nTrue Negatives: 7136\nFalse Positives: 319\nFalse Negatives: 1777\nTotal: 9790\nAccuracy: 0.7859039836567926\nRecall: 0.23897216274089936\nPrecision:  0.636259977194983\nF1 score: 0.34744707347447074\nAUC: 0.7184441364713836\nModel: gbpredictions\nTrue Positives: 1324\nTrue Negatives: 7093\nFalse Positives: 362\nFalse Negatives: 1011\nTotal: 9790\nAccuracy: 0.8597548518896834\nRecall: 0.5670235546038543\nPrecision:  0.7852906287069988\nF1 score: 0.6585426510818204\nAUC: 0.8302687102073987\n\n\n","datasetInfos":[],"metadata":{},"name":null,"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["for model in [\"lrpredictions\", \"dtpredictions\", \"rfpredictions\", \"nbpredictions\", \"gbpredictions\"]:\n","    df = globals()[model]\n","    \n","    tp = df[(df.label == 1) & (df.prediction == 1)].count()\n","    tn = df[(df.label == 0) & (df.prediction == 0)].count()\n","    fp = df[(df.label == 0) & (df.prediction == 1)].count()\n","    fn = df[(df.label == 1) & (df.prediction == 0)].count()\n","    a = ((tp + tn)/df.count())\n","    \n","    if(tp + fn == 0.0):\n","        r = 0.0\n","        p = float(tp) / (tp + fp)\n","    elif(tp + fp == 0.0):\n","        r = float(tp) / (tp + fn)\n","        p = 0.0\n","    else:\n","        r = float(tp) / (tp + fn)\n","        p = float(tp) / (tp + fp)\n","    \n","    if(p + r == 0):\n","        f1 = 0\n","    else:\n","        f1 = 2 * ((p * r)/(p + r))\n","    \n","    print(\"Model:\", model)\n","    print(\"True Positives:\", tp)\n","    print(\"True Negatives:\", tn)\n","    print(\"False Positives:\", fp)\n","    print(\"False Negatives:\", fn)\n","    print(\"Total:\", df.count())\n","    print(\"Accuracy:\", a)\n","    print(\"Recall:\", r)\n","    print(\"Precision: \", p)\n","    print(\"F1 score:\", f1)\n","    print('AUC:', BinaryClassificationMetrics(df['label','prediction'].rdd).areaUnderROC)\n","print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0c08e919-8234-444a-80e5-4131e4539d26","showTitle":false,"title":""}},"source":["## Section 4) Save Your Transformation Pipeline and Model(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"aad58ccf-bb39-4395-929f-13797841dc53","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/epsilon/rosh/extra/pipeline/metadata/</td><td>metadata/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/epsilon/rosh/extra/pipeline/stages/</td><td>stages/</td><td>0</td><td>0</td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[["dbfs:/mnt/epsilon/rosh/extra/pipeline/metadata/","metadata/",0,0],["dbfs:/mnt/epsilon/rosh/extra/pipeline/stages/","stages/",0,0]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"path","type":"\"string\""},{"metadata":"{}","name":"name","type":"\"string\""},{"metadata":"{}","name":"size","type":"\"long\""},{"metadata":"{}","name":"modificationTime","type":"\"long\""}],"type":"table"}},"output_type":"display_data"}],"source":["#Save the pipeline\n","pipelineModel.save(\"/mnt/epsilon/rosh/extra/pipeline\")\n","display(dbutils.fs.ls(\"/mnt/epsilon/rosh/extra/pipeline\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"0a1ecad6-6701-46a9-8cb6-c7dc77797783","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/epsilon/rosh/extra/models/DecisionTree/</td><td>DecisionTree/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/epsilon/rosh/extra/models/GBTree/</td><td>GBTree/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/epsilon/rosh/extra/models/LogisticRegression/</td><td>LogisticRegression/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/epsilon/rosh/extra/models/NaiveBayes/</td><td>NaiveBayes/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/epsilon/rosh/extra/models/RandomForest/</td><td>RandomForest/</td><td>0</td><td>0</td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[["dbfs:/mnt/epsilon/rosh/extra/models/DecisionTree/","DecisionTree/",0,0],["dbfs:/mnt/epsilon/rosh/extra/models/GBTree/","GBTree/",0,0],["dbfs:/mnt/epsilon/rosh/extra/models/LogisticRegression/","LogisticRegression/",0,0],["dbfs:/mnt/epsilon/rosh/extra/models/NaiveBayes/","NaiveBayes/",0,0],["dbfs:/mnt/epsilon/rosh/extra/models/RandomForest/","RandomForest/",0,0]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"path","type":"\"string\""},{"metadata":"{}","name":"name","type":"\"string\""},{"metadata":"{}","name":"size","type":"\"long\""},{"metadata":"{}","name":"modificationTime","type":"\"long\""}],"type":"table"}},"output_type":"display_data"}],"source":["#save the models\n","lrcvModel.save(\"/mnt/epsilon/rosh/extra/models/LogisticRegression\")\n","nbcvModel.save(\"/mnt/epsilon/rosh/extra/models/NaiveBayes\")\n","dtcvModel.save(\"/mnt/epsilon/rosh/extra/models/DecisionTree\")\n","rfcvModel.save(\"/mnt/epsilon/rosh/extra/models/RandomForest\")\n","gbcvModel.save(\"/mnt/epsilon/rosh/extra/models/GBTree\")\n","\n","display(dbutils.fs.ls(\"/mnt/epsilon/rosh/extra/models\"))"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Trying other models","notebookOrigID":3128781507651147,"widgets":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}
